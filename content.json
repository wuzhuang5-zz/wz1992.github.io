{"meta":{"title":"JohnWu'Blog","subtitle":"看看是啥","description":null,"author":"wuzhuang","url":"http://yoursite.com"},"pages":[{"title":"关于我","date":"2019-01-08T07:33:30.000Z","updated":"2019-01-08T07:35:17.238Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"我就是我"},{"title":"欢迎留言","date":"2019-01-08T08:31:39.000Z","updated":"2019-01-08T08:36:31.036Z","comments":true,"path":"guestbook/index.html","permalink":"http://yoursite.com/guestbook/index.html","excerpt":"","text":""},{"title":"分类","date":"2019-01-06T10:37:56.000Z","updated":"2019-01-07T09:39:19.130Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-01-07T09:41:49.000Z","updated":"2019-01-07T09:43:19.230Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"二分法变体","slug":"二分法变体","date":"2019-01-11T08:12:01.000Z","updated":"2019-01-11T09:01:39.719Z","comments":true,"path":"2019/01/11/二分法变体/","link":"","permalink":"http://yoursite.com/2019/01/11/二分法变体/","excerpt":"","text":"","categories":[{"name":"查找","slug":"查找","permalink":"http://yoursite.com/categories/查找/"}],"tags":[{"name":"search","slug":"search","permalink":"http://yoursite.com/tags/search/"}]},{"title":"二分法","slug":"二分法","date":"2019-01-11T02:52:00.000Z","updated":"2019-01-11T09:01:23.758Z","comments":true,"path":"2019/01/11/二分法/","link":"","permalink":"http://yoursite.com/2019/01/11/二分法/","excerpt":"时间复杂度为O(logn)的神奇算法","text":"时间复杂度为O(logn)的神奇算法 二分查找的迭代实现 12345678910111213141516171819public class Bsearch &#123; public int bSearch(int[] nums, int value) &#123; if(nums.length &lt;= 1) &#123; return value; &#125; int low = 0, high = nums.length - 1, mid = 0; while(low &lt;= high) &#123; mid = low + (high - low) / 2; if(nums[mid] == value) &#123; return mid; &#125; else if(nums[mid] &lt; value)&#123; low = high + 1; &#125; else &#123; high = low - 1; &#125; &#125; return -1; &#125;&#125; 二分查找的递归实现 12345678910111213141516171819public class Bsearch &#123; public int bSearch(int[] nums, int value) &#123; return bSearchInner(nums, 0, nums.length - 1, value); &#125; private int bSearchInner(int[] nums, int low, int high, int value) &#123; if (low &gt; high) &#123; return -1; &#125; int mid = low + (high - low) / 2; if (nums[mid] == value) &#123; return mid; &#125; else if (nums[mid] &lt; value) &#123; return bSearchInner(nums, mid + 1, high, value); &#125; else &#123; return bSearchInner(nums, low, mid - 1, value); &#125; &#125;&#125;","categories":[{"name":"查找","slug":"查找","permalink":"http://yoursite.com/categories/查找/"}],"tags":[{"name":"搜索","slug":"搜索","permalink":"http://yoursite.com/tags/搜索/"}]},{"title":"跳表","slug":"跳表","date":"2019-01-11T02:39:42.000Z","updated":"2019-01-13T11:02:50.519Z","comments":true,"path":"2019/01/11/跳表/","link":"","permalink":"http://yoursite.com/2019/01/11/跳表/","excerpt":"基于单链表实现的二分法时间复杂度仅为O(logn)，redis中的有序集合(Sorted Set)就是用跳表来实现的。","text":"基于单链表实现的二分法时间复杂度仅为O(logn)，redis中的有序集合(Sorted Set)就是用跳表来实现的。 对于一个单链表来说，即使数据是有序的，但是查找某个数还得遍历一遍链表，时间复杂度为O(n)。 那怎么来提高查找效率呢？可以对链表建立一级索引，每两个结点提取一个结点到上一级，我们把抽出来的那一级叫做索引或索引层。 如果我们要查找某个结点，比如16。我们可以先在索引层遍历，当遍历到索引层中值为13的结点时，我们发现下一个结点是17，那么要查找的结点16肯定在这两个结点之间。然后我们通过索引层结点的down指针，下降到原始链表这一层，继续遍历。这个时候，我们只需要再遍历2个结点，就可以找到值等于16的这个结点了。这样，原来如果要查找16，需要遍历10个结点，现在只需要遍历7个结点。 跟前面建立一级索引的方式类似，我们在第一层索引上，每两个结点就抽取一个结点到二层索引。 这种链表加多级索引的结构，就是跳表。时间复杂度为O(logn)空间复杂度为O(n) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114public class SkipList &#123; private static final int MAX_LEVEL = 16; private int levelCount = 1; private Node head = new Node(); private Random r = new Random(); public Node find(int value) &#123; Node p = head; for (int i = levelCount - 1; i &gt;= 0; --i) &#123; while (p.forwards[i] != null &amp;&amp; p.forwards[i].data &lt; value) &#123; p = p.forwards[i]; &#125; &#125; if (p.forwards[0] != null &amp;&amp; p.forwards[0].data == value) &#123; return p.forwards[0]; &#125; else &#123; return null; &#125; &#125; public void insert(int value) &#123; int level = randomLevel(); Node newNode = new Node(); newNode.data = value; newNode.maxLevel = level; Node update[] = new Node[level]; for (int i = 0; i &lt; level; ++i) &#123; update[i] = head; &#125; // record every level largest value which smaller than insert value in update[] Node p = head; for (int i = level - 1; i &gt;= 0; --i) &#123; while (p.forwards[i] != null &amp;&amp; p.forwards[i].data &lt; value) &#123; p = p.forwards[i]; &#125; update[i] = p;// use update save node in search path &#125; // in search path node next node become new node forwords(next) for (int i = 0; i &lt; level; ++i) &#123; newNode.forwards[i] = update[i].forwards[i]; update[i].forwards[i] = newNode; &#125; // update node hight if (levelCount &lt; level) &#123; levelCount = level; &#125; &#125; public void delete(int value) &#123; Node[] update = new Node[levelCount]; Node p = head; for (int i = levelCount - 1; i &gt;= 0; --i) &#123; while (p.forwards[i] != null &amp;&amp; p.forwards[i].data &lt; value) &#123; p = p.forwards[i]; &#125; update[i] = p; &#125; if (p.forwards[0] != null &amp;&amp; p.forwards[0].data == value) &#123; for (int i = levelCount - 1; i &gt;= 0; --i) &#123; if (update[i].forwards[i] != null &amp;&amp; update[i].forwards[i].data == value) &#123; update[i].forwards[i] = update[i].forwards[i].forwards[i]; &#125; &#125; &#125; &#125; // 随机 level 次，如果是奇数层数 +1，防止伪随机 private int randomLevel() &#123; int level = 1; for (int i = 1; i &lt; MAX_LEVEL; ++i) &#123; if (r.nextInt() % 2 == 1) &#123; level++; &#125; &#125; return level; &#125; public void printAll() &#123; Node p = head; while (p.forwards[0] != null) &#123; System.out.print(p.forwards[0] + \" \"); p = p.forwards[0]; &#125; System.out.println(); &#125; public class Node &#123; private int data = -1; private Node forwards[] = new Node[MAX_LEVEL]; private int maxLevel = 0; @Override public String toString() &#123; StringBuilder builder = new StringBuilder(); builder.append(\"&#123; data: \"); builder.append(data); builder.append(\"; levels: \"); builder.append(maxLevel); builder.append(\" &#125;\"); return builder.toString(); &#125; &#125;&#125;","categories":[{"name":"跳表","slug":"跳表","permalink":"http://yoursite.com/categories/跳表/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/数据结构/"}]},{"title":"队列","slug":"队列","date":"2019-01-09T08:31:09.000Z","updated":"2019-01-09T08:31:09.851Z","comments":true,"path":"2019/01/09/队列/","link":"","permalink":"http://yoursite.com/2019/01/09/队列/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"栈","slug":"栈","date":"2019-01-09T08:30:57.000Z","updated":"2019-01-09T11:27:36.558Z","comments":true,"path":"2019/01/09/栈/","link":"","permalink":"http://yoursite.com/2019/01/09/栈/","excerpt":"先进后出，后进先出是栈的特性，本文分别使用数组和链表来实现。","text":"先进后出，后进先出是栈的特性，本文分别使用数组和链表来实现。 顺序栈用数组实现 12345678910111213141516171819202122public class Stack &#123; //栈中元素个数 private int size; //默认栈的容量 private static int capacity = 1024; private Object[] stack = new Object[capacity]; //入栈 public boolean push(Object value) &#123; if(size &gt;= n) &#123; return false; &#125; stack[size++] = value; return true; &#125; //出栈 public Object pop() &#123; if(size == 0) &#123; return null; &#125; return stack[size--]; &#125;&#125; 链式栈123456789101112131415161718192021222324252627282930313233public class Stack &#123; //头结点 private ListNode head = null; //结点数 private int size; public void push (Object value) &#123; ListNode newNode = new ListNode(value); if(head == null) &#123; head = newNode; &#125; else &#123; newNode.next = head; head = newNode; &#125; size++; &#125; public Object pop () &#123; if(size == 0) &#123; return null; &#125; Object value = head.value; head = head.next; return value; &#125; static class ListNode &#123; private Object value; private ListNode next; public ListNode(Object value) &#123; this.value = value; &#125; &#125;&#125;","categories":[{"name":"链表","slug":"链表","permalink":"http://yoursite.com/categories/链表/"},{"name":"数组","slug":"数组","permalink":"http://yoursite.com/categories/数组/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/数据结构/"}]},{"title":"数据库原理","slug":"数据库原理","date":"2019-01-08T10:48:28.000Z","updated":"2019-01-09T08:25:46.800Z","comments":true,"path":"2019/01/08/数据库原理/","link":"","permalink":"http://yoursite.com/2019/01/08/数据库原理/","excerpt":"底层和上层数据库组件概况 查询优化过程概况 事务和缓冲池管理概况","text":"底层和上层数据库组件概况 查询优化过程概况 事务和缓冲池管理概况 回到基础很久很久以前（在一个遥远而又遥远的星系……)，开发者必须确切地知道他们的代码需要多少次运算。他们把算法和数据结构牢记于心，因为他们的计算机运行缓慢，无法承受对CPU和内存的浪费。 在这一部分，我将提醒大家一些这类的概念，因为它们对理解数据库至关重要。我还会介绍数据库索引的概念。 O(1) vs O(n^2)时间复杂度用来检验某个算法处理一定量的数据要花多长时间。为了描述这个复杂度，计算机科学家使用数学上的『简明解释算法中的大O符号』。这个表示法用一个函数来描述算法处理给定的数据需要多少次运算。 比如，当我说『这个算法是适用 O(某函数())』，我的意思是对于某些数据，这个算法需要 某函数(数据量) 次运算来完成。 重要的不是数据量，而是当数据量增加时运算如何增加。时间复杂度不会给出确切的运算次数，但是给出的是一种理念。 例子数据量低时，O(1) 和 O(n^2)的区别可以忽略不计。比如，你有个算法要处理2000条元素。 O(1) 算法会消耗 1 次运算 O(log(n)) 算法会消耗 7 次运算 O(n) 算法会消耗 2000 次运算 O(n*log(n)) 算法会消耗 14,000 次运算 O(n^2) 算法会消耗 4,000,000 次运算 O(1) 和 O(n^2) 的区别似乎很大（4百万）,但你最多损失 2 毫秒，只是一眨眼的功夫。确实，当今处理器每秒可处理上亿次的运算。这就是为什么性能和优化在很多IT项目中不是问题。 但是面临海量数据的时候，了解这个概念依然很重要。如果这一次算法需要处理 1,000,000 条元素（这对数据库来说也不算大）。 O(1) 算法会消耗 1 次运算 O(log(n)) 算法会消耗 14 次运算 O(n) 算法会消耗 1,000,000 次运算 O(n*log(n)) 算法会消耗 14,000,000 次运算 O(n^2) 算法会消耗 1,000,000,000,000 次运算 继续深入了解下数据库所用到的数据结构 搜索一个均衡的树会得到 O(log(n)) 复杂度 搜索一个阵列会得到 O(n) 复杂度 最好的排序算法具有 O(n*log(n)) 复杂度 糟糕的排序算法具有 O(n^2) 复杂度 合并排序参考http://wwdan.com/2019/01/07/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/ 阵列二维阵列是最简单的数据结构。一个表可以看作是个阵列，比如： 每个行代表一个主体 列用来描述主体的特征 每个列保存某一种类型对数据（整数、字符串、日期……） 虽然用这个方法保存和视觉化数据很棒，但是当你要查找特定的值它就很糟糕了。 举个例子，如果你要找到所有在 UK 工作的人，你必须查看每一行以判断该行是否属于 UK 。这会造成 N 次运算的成本（N 等于行数），还不赖嘛，但是有没有更快的方法呢？这时候树就可以登场了（或开始起作用了）。 树和数据库索引二叉查找树是带有特殊属性的树，每个节点必须保证： 比保存在左子树的任何值都要大 比保存在右子树的任何值都要小 这个树有 N=15 个元素。比方说我要找208： 我从键值为 136 的根开始，因为 136&lt;208，我去找节点136的右子树。 398&gt;208，所以我去找节点398的左子树 250&gt;208，所以我去找节点250的左子树 200&lt;208，所以我去找节点200的右子树。但是 200 没有右子树，值不存在（因为如果存在，它会在 200 的右子树） 现在比方说我要找40 我从键值为136的根开始，因为 136&gt;40，所以我去找节点136的左子树。 80&gt;40，所以我去找节点 80 的左子树 40=40，节点存在。我抽取出节点内部行的ID（图中没有画）再去表中查找对应的 ROW ID。 知道 ROW ID我就知道了数据在表中对精确位置，就可以立即获取数据。 时间复杂度为O(logN) B+树索引查找一个特定值这个树挺好用，但是当你需要查找两个值之间的多个元素时，就会有大麻烦了。你的成本将是 O(N)，因为你必须查找树的每一个节点，以判断它是否处于那 2 个值之间（例如，对树使用中序遍历）。而且这个操作不是磁盘I/O有利的，因为你必须读取整个树。我们需要找到高效的范围查询方法。为了解决这个问题，现代数据库使用了一种修订版的树，叫做B+树。在一个B+树里： 只有最底层的节点（叶子节点）才保存信息（相关表的行位置） 其它节点只是在搜索中用来指引到正确节点的。 你可以看到，节点更多了（多了两倍）。确实，你有了额外的节点，它们就是帮助你找到正确节点的『决策节点』（正确节点保存着相关表中行的位置）。但是搜索复杂度还是在 O(log(N))（只多了一层）。一个重要的不同点是，最底层的节点是跟后续节点相连接的。 用这个 B+树，假设你要找40到100间的值： 你只需要找 40（若40不存在则找40之后最贴近的值），就像你在上一个树中所做的那样。 然后用那些连接来收集40的后续节点，直到找到100。 比方说你找到了 M 个后续节点，树总共有 N 个节点。对指定节点的搜索成本是 log(N)，跟上一个树相同。但是当你找到这个节点，你得通过后续节点的连接得到 M 个后续节点，这需要 M 次运算。那么这次搜索只消耗了 M+log(N) 次运算，区别于上一个树所用的 N 次运算。此外，你不需要读取整个树（仅需要读 M+log(N) 个节点）,这意味着更少的磁盘访问。如果 M 很小（比如 200 行）并且 N 很大（1,000,000），那结果就是天壤之别了。 哈希表当你想快速查找值时，哈希表是非常有用的。而且，理解哈希表会帮助我们接下来理解一个数据库常见的联接操作，叫做『哈希联接』。这个数据结构也被数据库用来保存一些内部的东西（比如锁表或者缓冲池，我们在下文会研究这两个概念）。 哈希表这种数据结构可以用关键字来快速找到一个元素。为了构建一个哈希表，你需要定义： 元素的关键字 关键字的哈希函数。关键字计算出来的哈希值给出了元素的位置（叫做哈希桶）。 关键字比较函数。一旦你找到正确的哈希桶，你必须用比较函数在桶内找到你要的元素。 如果有了好的哈希函数，在哈希表里搜索的时间复杂度是 O(1)。 全局概览我们已经了解了数据库内部的基本组件，现在我们需要回来看看数据库的全貌了。 数据库是一个易于访问和修改的信息集合。不过简单的一堆文件也能达到这个效果。事实上，像SQLite这样最简单的数据库也只是一堆文件而已，但SQLite是精心设计的一堆文件，因为它允许你： 使用事务来确保数据的安全和一致性 快速处理百万条以上的数据 核心组件： 进程管理器（process manager）：很多数据库具备一个需要妥善管理的进程/线程池。再者，为了实现纳秒级操作，一些现代数据库使用自己的线程而不是操作系统线程。 网络管理器（network manager）：网路I/O是个大问题，尤其是对于分布式数据库。所以一些数据库具备自己的网络管理器。 文件系统管理器（File system manager）：磁盘I/O是数据库的首要瓶颈。具备一个文件系统管理器来完美地处理OS文件系统甚至取代OS文件系统，是非常重要的。 内存管理器（memory manager）：为了避免磁盘I/O带来的性能损失，需要大量的内存。但是如果你要处理大容量内存你需要高效的内存管理器，尤其是你有很多查询同时使用内存的时候。 安全管理器（Security Manager）：用于对用户的验证和授权。 客户端管理器（Client manager）：用于管理客户端连接。 …… 工具： 备份管理器（Backup manager）：用于保存和恢复数据。 复原管理器（Recovery manager）：用于崩溃后重启数据库到一个一致状态。 监控管理器（Monitor manager）：用于记录数据库活动信息和提供监控数据库的工具。 Administration管理器（Administration manager）：用于保存元数据（比如表的名称和结构），提供管理数据库、模式、表空间的工具。【译者注：好吧，我真的不知道Administration manager该翻译成什么，有知道的麻烦告知，不胜感激……】 …… 查询管理器： 查询解析器（Query parser）：用于检查查询是否合法 查询重写器（Query rewriter）：用于预优化查询 查询优化器（Query optimizer）：用于优化查询 查询执行器（Query executor）：用于编译和执行查询 数据管理器： 事务管理器（Transaction manager）：用于处理事务 缓存管理器（Cache manager）：数据被使用之前置于内存，或者数据写入磁盘之前置于内存 数据访问管理器（Data access manager）：访问磁盘中的数据 客户端管理器 客户端管理器是处理客户端通信的。客户端可以是一个（网站）服务器或者一个最终用户或最终应用。客户端管理器通过一系列知名的API（JDBC, ODBC, OLE-DB …）提供不同的方式来访问数据库。 客户端管理器也提供专有的数据库访问API。 当你连接到数据库时： 管理器首先检查你的验证信息（用户名和密码），然后检查你是否有访问数据库的授权。 然后，管理器检查是否有空闲进程（或线程）来处理你对查询。 管理器还会检查数据库是否负载很重。 管理器可能会等待一会儿来获取需要的资源。如果等待时间达到超时时间，它会关闭连接并给出一个可读的错误信息。 然后管理器会把你的查询送给查询管理器来处理。 因为查询处理进程不是不全则无的，一旦它从查询管理器得到数据，它会把部分结果保存到一个缓冲区并且开始给你发送。 如果遇到问题，管理器关闭连接，向你发送可读的解释信息，然后释放资源。 查询管理器 在这部分里，一个写得糟糕的查询可以转换成一个快速执行的代码，代码执行的结果被送到客户端管理器。这个多步骤操作过程如下： 查询首先被解析并判断是否合法 然后被重写，去除了无用的操作并且加入预优化部分 接着被优化以便提升性能，并被转换为可执行代码和数据访问计划。 然后计划被编译 最后，被执行 查询解析器每一条SQL语句都要送到解析器来检查语法，如果你的查询有错，解析器将拒绝该查询。比如，如果你写成”SLECT …” 而不是 “SELECT …”，那就没有下文了。 但这还不算完，解析器还会检查关键字是否使用正确的顺序，比如 WHERE 写在 SELECT 之前会被拒绝。 然后，解析器要分析查询中的表和字段，使用数据库元数据来检查： 表是否存在 表的字段是否存在 对某类型字段的运算是否可能（比如，你不能将整数和字符串进行比较，你不能对一个整数使用 substring() 函数） 接着，解析器检查在查询中你是否有权限来读取（或写入）表。 在解析过程中，SQL 查询被转换为内部表示（通常是一个树）。 如果一切正常，内部表示被送到查询重写器。 查询重写器 预优化查询 避免不必要的运算 帮助优化器找到合理的最佳解决方案 重写器按照一系列已知的规则对查询执行检测。如果查询匹配一种模式的规则，查询就会按照这条规则来重写。下面是（可选）规则的非详尽的列表： 视图合并：如果你在查询中使用视图，视图就会转换为它的 SQL 代码。 子查询扁平化：子查询是很难优化的，因此重写器会尝试移除子查询 去除不必要的运算符：比如，如果你用了 DISTINCT，而其实你有 UNIQUE 约束（这本身就防止了数据出现重复），那么 DISTINCT 关键字就被去掉了。 排除冗余的联接：如果相同的 JOIN 条件出现两次，比如隐藏在视图中的 JOIN 条件，或者由于传递性产生的无用 JOIN，都会被消除。 常数计算赋值：如果你的查询需要计算，那么在重写过程中计算会执行一次。比如 WHERE AGE &gt; 10+2 会转换为 WHERE AGE &gt; 12 ， TODATE(“日期字符串”) 会转换为 datetime 格式的日期值。 查询优化器大多数时候瓶颈都在磁盘IO不在CPU上。 存取路径 在应用联接运算符之前，你首先需要获得数据。以下就是获得数据的方法 全扫描： 如果你读过执行计划，一定看到过『全扫描』（或只是『扫描』）一词。简单的说全扫描就是数据库完整的读一个表或索引。就磁盘 I/O 而言，很明显全表扫描的成本比索引全扫描要高昂。 范围扫描：其他类型的扫描有索引范围扫描，比如当你使用谓词 ” WHERE AGE &gt; 20 AND AGE &lt; 40 ” 的时候它就会发生。当然，你需要在 AGE 字段上有索引才能用到索引范围扫描。范围查询的时间成本大约是 log(N)+M，这里 N 是索引的数据量，M 是范围内估测的行数。 唯一扫描： 1SELECT LASTNAME, FIRSTNAME from PERSON WHERE AGE = 28 如果 person 表的 age 列有索引，优化器会使用索引找到所有年龄为 28 的人，然后它会去表中读取相关的行，这是因为索引中只有 age 的信息而你要的是姓和名。 查询执行器在这个阶段，我们有了一个优化的执行计划，再编译为可执行代码。然后，如果有足够资源（内存，CPU），查询执行器就会执行它。计划中的操作符 (JOIN, SORT BY …) 可以顺序或并行执行，这取决于执行器。为了获得和写入数据，查询执行器与数据管理器交互，本文下一部分来讨论数据管理器。 数据管理器 在这一步，查询管理器执行了查询，需要从表和索引获取数据，于是向数据管理器提出请求。但是有 2 个问题： 关系型数据库使用事务模型，所以，当其他人在同一时刻使用或修改数据时，你无法得到这部分数据。 数据提取是数据库中速度最慢的操作，所以数据管理器需要足够聪明地获得数据并保存在内存缓冲区内。 缓存管理器 查询执行器不会直接从文件系统拿数据，而是向缓存管理器要。缓存管理器有一个内存缓存区，叫做缓冲池，从内存读取数据显著地提升数据库性能。然而，这导致了另一个问题（数据库总是这样…)，缓存管理器需要在查询执行器使用数据之前得到数据，否则查询管理器不得不等待数据从缓慢的磁盘中读出来。 这个问题叫预读。查询执行器知道它将需要什么数据，因为它了解整个查询流，而且通过统计也了解磁盘上的数据。道理是这样的： 当查询执行器处理它的第一批数据时 会告诉缓存管理器预先装载第二批数据 当开始处理第二批数据时 告诉缓存管理器预先装载第三批数据，并且告诉缓存管理器第一批可以从缓存里清掉了。 …… 缓存管理器在缓冲池里保存所有的这些数据。为了确定一条数据是否有用，缓存管理器给缓存的数据添加了额外的信息。 有时查询执行器不知道它需要什么数据，有的数据库也不提供这个功能。相反，它们使用一种推测预读法（比如：如果查询执行器想要数据1、3、5，它不久后很可能会要 7、9、11），或者顺序预读法（这时候缓存管理器只是读取一批数据后简单地从磁盘加载下一批连续数据）。 为了监控预读的工作状况，现代数据库引入了一个度量叫缓冲/缓存命中率，用来显示请求的数据在缓存中找到而不是从磁盘读取的频率。 缓存只是容量有限的内存空间，因此，为了加载新的数据，它需要移除一些数据。加载和清除缓存需要一些磁盘和网络I/O的成本。如果你有个经常执行的查询，那么每次都把查询结果加载然后清除，效率就太低了。现代数据库用缓冲区置换策略来解决这个问题。 LRU LRU代表最近最少使用（Least Recently Used）算法，背后的原理是：在缓存里保留的数据是最近使用的，所以更有可能再次使用。 事务管理器一个ACID事务是一个工作单元，它要保证4个属性： 原子性（Atomicity）: 事务『要么全部完成，要么全部取消』，即使它持续运行10个小时。如果事务崩溃，状态回到事务之前（事务回滚）。 隔离性（Isolation）: 如果2个事务 A 和 B 同时运行，事务 A 和 B 最终的结果是相同的，不管 A 是结束于 B 之前/之后/运行期间。 持久性（Durability）: 一旦事务提交（也就是成功执行）,不管发生什么（崩溃或者出错），数据要保存在数据库中。 一致性（Consistency）: 只有合法的数据（依照关系约束和函数约束）能写入数据库，一致性与原子性和隔离性有关。 在同一个事务内，你可以运行多个SQL查询来读取、创建、更新和删除数据。当两个事务使用相同的数据，麻烦就来了。经典的例子是从账户A到账户B的汇款。假设有2个事务： 事务1（T1）从账户A取出100美元给账户B 事务2（T2）从账户A取出50美元给账户B 我们回来看看ACID属性： 原子性确保不管 T1 期间发生什么（服务器崩溃、网络中断…），你不能出现账户A 取走了100美元但没有给账户B 的现象（这就是数据不一致状态）。 隔离性确保如果 T1 和 T2 同时发生，最终A将减少150美元，B将得到150美元，而不是其他结果，比如因为 T2 部分抹除了 T1 的行为，A减少150美元而B只得到50美元（这也是不一致状态）。 持久性确保如果 T1 刚刚提交，数据库就发生崩溃，T1 不会消失得无影无踪。 一致性确保钱不会在系统内生成或灭失。 现代数据库不会使用纯粹的隔离作为默认模式，因为它会带来巨大的性能消耗。SQL一般定义4个隔离级别： 串行化(Serializable，SQLite默认模式）：最高级别的隔离。两个同时发生的事务100%隔离，每个事务有自己的『世界』。 可重复读（Repeatable read，MySQL默认模式）：每个事务有自己的『世界』，除了一种情况。如果一个事务成功执行并且添加了新数据，这些数据对其他正在执行的事务是可见的。但是如果事务成功修改了一条数据，修改结果对正在运行的事务不可见。所以，事务之间只是在新数据方面突破了隔离，对已存在的数据仍旧隔离。举个例子，如果事务A运行”SELECT count(1) from TABLE_X” ，然后事务B在 TABLE_X 加入一条新数据并提交，当事务A再运行一次 count(1)结果不会是一样的。这叫幻读（phantom read）。 读取已提交（Read committed，Oracle、PostgreSQL、SQL Server默认模式）：可重复读+新的隔离突破。如果事务A读取了数据D，然后数据D被事务B修改（或删除）并提交，事务A再次读取数据D时数据的变化（或删除）是可见的。这叫不可重复读（non-repeatable read）。 读取未提交（Read uncommitted）：最低级别的隔离，是读取已提交+新的隔离突破。如果事务A读取了数据D，然后数据D被事务B修改（但并未提交，事务B仍在运行中），事务A再次读取数据D时，数据修改是可见的。如果事务B回滚，那么事务A第二次读取的数据D是无意义的，因为那是事务B所做的从未发生的修改（已经回滚了嘛）。这叫脏读（dirty read）。 并发控制确保隔离性、一致性和原子性的真正问题是对相同数据的写操作（增、更、删）： 如果所有事务只是读取数据，它们可以同时工作，不会更改另一个事务的行为。 如果（至少）有一个事务在修改其他事务读取的数据，数据库需要找个办法对其它事务隐藏这种修改。而且，它还需要确保这个修改操作不会被另一个看不到这些数据修改的事务擦除。 这个问题叫并发控制。 最简单的解决办法是依次执行每个事务（即顺序执行），但这样就完全没有伸缩性了，在一个多处理器/多核服务器上只有一个核心在工作，效率很低。 理想的办法是，每次一个事务创建或取消时： 监控所有事务的所有操作 检查是否2个（或更多）事务的部分操作因为读取/修改相同的数据而存在冲突 重新编排冲突事务中的操作来减少冲突的部分 按照一定的顺序执行冲突的部分（同时非冲突事务仍然在并发运行） 考虑事务有可能被取消 用更正规的说法，这是对冲突的调度问题。更具体点儿说，这是个非常困难而且CPU开销很大的优化问题。企业级数据库无法承担等待几个小时，来寻找每个新事务活动最好的调度，因此就使用不那么理想的方式以避免更多的时间浪费在解决冲突上。 锁管理器为了解决这个问题，多数数据库使用锁和/或数据版本控制。 悲观锁 原理是： 如果一个事务需要一条数据 它就把数据锁住 如果另一个事务也需要这条数据 它就必须要等第一个事务释放这条数据这个锁叫排他锁。 但是对一个仅仅读取数据的事务使用排他锁非常昂贵，因为这会迫使其它只需要读取相同数据的事务等待。因此就有了另一种锁，共享锁。 共享锁是这样的： 如果一个事务只需要读取数据A 它会给数据A加上『共享锁』并读取 如果第二个事务也需要仅仅读取数据A 它会给数据A加上『共享锁』并读取 如果第三个事务需要修改数据A 它会给数据A加上『排他锁』，但是必须等待另外两个事务释放它们的共享锁。 同样的，如果一块数据被加上排他锁，一个只需要读取该数据的事务必须等待排他锁释放才能给该数据加上共享锁。 锁管理器是添加和释放锁的进程，在内部用一个哈希表保存锁信息（关键字是被锁的数据），并且了解每一块数据是： 被哪个事务加的锁 哪个事务在等待数据解锁 死锁 但是使用锁会导致一种情况，2个事务永远在等待一块数据： 在本图中： 事务A 给 数据1 加上排他锁并且等待获取数据2 事务B 给 数据2 加上排他锁并且等待获取数据1 在死锁发生时，锁管理器要选择取消（回滚）一个事务，以便消除死锁。这可是个艰难的决定： 杀死数据修改量最少的事务（这样能减少回滚的成本）？ 杀死持续时间最短的事务，因为其它事务的用户等的时间更长？ 杀死能用更少时间结束的事务（避免可能的资源饥荒）？ 一旦发生回滚，有多少事务会受到回滚的影响？ InnoDB提供了一个机制，在两个事务相互等待时，当一个等待时间超过设置的某一阀值时，对其中一个事务进行回滚，另一个事务就能继续执行。这种方法简单有效，在innodb中，参数innodb_lock_wait_timeout用来设置超时时间。","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/数据库/"}]},{"title":"链表","slug":"链表","date":"2019-01-07T09:29:41.000Z","updated":"2019-01-09T08:27:16.015Z","comments":true,"path":"2019/01/07/链表/","link":"","permalink":"http://yoursite.com/2019/01/07/链表/","excerpt":"链表初探","text":"链表初探 单链表 链表通过指针将一组零散的内存块串联在一起。其中，内存块称为链表的结点。为了将所有的结点串联起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址。 我们习惯把第一个结点叫做头结点，把最后一个结点叫做尾结点。其中，头结点用来记录链表的基地址。有了它，我们就可以遍历得到整条链表。而尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个空地址NULL，表示这是链表上最后一个结点。 但是，链表要随机访问第K个元素，就没有数组那么高效了。链表需要根据指针一个结点一个结点地依次遍历按，直到找到相应的结点，时间复杂度为O(n)。 循环链表循环链表和单链表的区别在尾结点，其尾结点的指针是指向链表的头结点。 双向链表双向链表每个结点有一个指向前面结点的指针prev和指向后面结点的指针next。 从结构上看，双向链表可以支持O(1)时间复杂度的情况下找到前驱结点，正是这样的特点，也使双向链表在某些情况下的插入、删除等操作比单链表简单、高效。链表删除无外乎两种情况： 删除结点种值等于某个给定值的结点 删除给定指针指向的结点对于第一种情况，需要遍历链表找到和给定值相等的结点，时间复杂度是O(n)对于第二种情况，已经知道给定结点的指针，删除需要知道前指针prev，单链表需要遍历，而双向链表不需要。同理，插入也是一样。 常见链表问题 单链表反转 链表中环的检测 两个有序链表合并 删除链表倒数第n个结点 求链表的中间结点 对应leetcode中的题号依次为：206、141、21、19、876","categories":[{"name":"链表","slug":"链表","permalink":"http://yoursite.com/categories/链表/"}],"tags":[{"name":"链表","slug":"链表","permalink":"http://yoursite.com/tags/链表/"}]},{"title":"数组","slug":"数组","date":"2019-01-07T09:29:05.000Z","updated":"2019-01-09T08:28:12.271Z","comments":true,"path":"2019/01/07/数组/","link":"","permalink":"http://yoursite.com/2019/01/07/数组/","excerpt":"","text":"","categories":[{"name":"数组","slug":"数组","permalink":"http://yoursite.com/categories/数组/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/数据结构/"}]},{"title":"快速排序","slug":"快速排序","date":"2019-01-07T07:02:13.000Z","updated":"2019-01-07T07:10:09.055Z","comments":true,"path":"2019/01/07/快速排序/","link":"","permalink":"http://yoursite.com/2019/01/07/快速排序/","excerpt":"采用分治思想，平均时间复杂度为O(nlogn)，不稳定排序","text":"采用分治思想，平均时间复杂度为O(nlogn)，不稳定排序","categories":[{"name":"排序","slug":"排序","permalink":"http://yoursite.com/categories/排序/"}],"tags":[]},{"title":"归并排序","slug":"归并排序","date":"2019-01-07T07:01:55.000Z","updated":"2019-01-08T07:29:54.787Z","comments":true,"path":"2019/01/07/归并排序/","link":"","permalink":"http://yoursite.com/2019/01/07/归并排序/","excerpt":"采用分治思想，时间复杂度为O(nlogn)且稳定的排序,空间复杂度为O(n)，可以实现原地排序","text":"采用分治思想，时间复杂度为O(nlogn)且稳定的排序,空间复杂度为O(n)，可以实现原地排序 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class MergeSort &#123; public static void mergeSort(int[] nums) &#123; mergeSortInner(nums, 0, nums.length - 1); &#125; //递归调用分解数组 public static void mergeSortInner(int[] nums, int l, int r) &#123; if (l &gt;= r) &#123; return; &#125; int q = l + (r - l) / 2; mergeSortInner(nums, l, q); mergeSortInner(nums, q + 1, r); merge(nums, l, q, r); &#125; //合并数组 public static void merge(int[] nums, int l, int q, int r) &#123; int i = l; int j = q + 1; int k = 0; int[] arr = new int[r - l + 1]; while (i &lt;= q &amp;&amp; j &lt;= r) &#123; if (nums[i] &lt;= nums[j]) &#123; arr[k++] = nums[i++]; &#125; else &#123; arr[k++] = nums[j++]; &#125; &#125; //将剩余的数拷贝到临时数组中 int start = i; int end = q; if (j &lt;= r) &#123; start = j; end = r; &#125; while (start &lt;= end) &#123; arr[k++] = nums[start++]; &#125; //将临时数组拷贝回原数组 for (i = 0; i &lt;= r - l; i++) &#123; nums[l+i] = arr[i]; &#125; &#125;&#125;","categories":[{"name":"排序","slug":"排序","permalink":"http://yoursite.com/categories/排序/"}],"tags":[{"name":"排序","slug":"排序","permalink":"http://yoursite.com/tags/排序/"}]},{"title":"三大简单排序","slug":"三大简单排序","date":"2019-01-06T10:16:11.000Z","updated":"2019-01-08T03:25:26.901Z","comments":true,"path":"2019/01/06/三大简单排序/","link":"","permalink":"http://yoursite.com/2019/01/06/三大简单排序/","excerpt":"三大简单排序：冒泡排序、插入排序、选择排序 平均时间复杂度均为O(n*n)","text":"三大简单排序：冒泡排序、插入排序、选择排序 平均时间复杂度均为O(n*n) 冒泡排序12345678910111213141516171819202122public class BubbleSort &#123; public static void bubbleSort(int[] nums) &#123; for(int i=0; i&lt;nums.length; i++) &#123; Boolean flag = true; for(int j=0; j&lt;nums.length-i-1; j++) &#123; if(nums[j] &gt; nums[j+1]) &#123; swap(nums, j, j+1); flag = false; &#125; &#125; if(flag) &#123; break; &#125; &#125; &#125; public static void swap(int[] nums, int i, int j) &#123; int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; &#125;&#125; 插入排序12345678910111213public static void insertSort(int[] nums) &#123; for(int i=1; i&lt;nums.length; i++) &#123; int value = nums[i]; int j=i-1; for(; j&gt;=0; j--) &#123; if(nums[j] &gt; value) &#123; nums[j+1] = nums[j]; &#125; else &#123; break; &#125; &#125; nums[j+1] = value; &#125; 选择排序1234567891011public static void selectSort(int[] nums) &#123; for(int i=0; i&lt;nums.length; i++) &#123; int min = i; for(int j=i; j&lt;nums.length; j++) &#123; if(nums[min] &gt; nums[j]) &#123; min = j; &#125; &#125; swap(nums, i, min); &#125; &#125;","categories":[{"name":"排序","slug":"排序","permalink":"http://yoursite.com/categories/排序/"}],"tags":[{"name":"sort","slug":"sort","permalink":"http://yoursite.com/tags/sort/"}]}]}